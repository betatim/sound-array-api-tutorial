{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce6ce95-d6a7-4ab5-80e8-576cbd2592f2",
   "metadata": {},
   "source": [
    "# Sound Effects\n",
    "\n",
    "Let's implement some simple sound effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19c869-db64-47d4-8172-b71de485bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "from IPython.display import Audio\n",
    "\n",
    "#from google.colab import output\n",
    "#output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd685fe-5644-42a9-9ba0-a8e30ff005af",
   "metadata": {},
   "source": [
    "## Recording some audio\n",
    "\n",
    "We need some sound to work on. Luckily we can just record something with the microphone in our computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90b226-6fc9-4e47-9b38-3615416060b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    camera = CameraStream(constraints={'audio': True, 'video': False})\n",
    "    recorder = AudioRecorder(stream=camera)\n",
    "    return recorder\n",
    "\n",
    "def convert_audio(recorder):\n",
    "    recorder.save(\"recording.webm\")\n",
    "    !ffmpeg -i recording.webm -ac 1 -f wav my_recording.wav -y -hide_banner -loglevel panic\n",
    "\n",
    "    rate, rec = scipy.io.wavfile.read(\"my_recording.wav\")\n",
    "\n",
    "    return rate, rec\n",
    "\n",
    "recorder = record_audio()\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611eecb1-20a3-44d9-81d8-d664d7c729de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate, audio = convert_audio(recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df705c71-f3dd-44dc-ac68-53e07737b139",
   "metadata": {},
   "source": [
    "## Speeding up a recording\n",
    "\n",
    "You all know the \"playback speed\" button on YouTube. Let's implement a simple version of this.\n",
    "\n",
    "When we record sound we create a set of samples. Typically something like 20000 samples per second. This means a one second\n",
    "recording contains about 20000 samples. To play back a recording at the right speed we need to know the sample rate,\n",
    "how many samples were recorded per second.\n",
    "\n",
    "To speed up a recording by ten percent we can take an existing 5second recording made of `100_000` samples and reduce the total number\n",
    "of samples to `100_000 / 1.1 = 90910` samples. When we then play back this smaller number of samples at the same rate, we will get\n",
    "a shorter recording.\n",
    "\n",
    "XXX insert diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c82a0b-24b7-4c21-a457-11269dd42aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def speed_up_audio(audio_data, factor=1.1):\n",
    "    \"\"\"Speed up recording by interpolation\n",
    "\n",
    "    The total number of samples is reduced by `factor` which leads\n",
    "    to a shorter recording when `factor>1`.\n",
    "    \"\"\"\n",
    "    new_audio = np.interp(\n",
    "        np.arange(0, len(audio_data), factor),\n",
    "        np.arange(len(audio_data)),\n",
    "        audio_data,\n",
    "    )\n",
    "    return new_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7351a-9bc8-4dba-8f93-de902bb6a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_audio = speed_up_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6142f2-6f10-4d59-b309-967b579e25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(fast_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae44a8a-d388-4e31-aa94-a481b09bcdb6",
   "metadata": {},
   "source": [
    "The basics work, so lets re-implement this using the array API so that it works with CuPy, PyTorch and Numpy arrays.\n",
    "\n",
    "The speed up function looks pretty straightforward so it should be easy to convert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25daaf8f-ab5e-4b3f-b5c2-f95ff8e40153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import array_api_compat\n",
    "\n",
    "\n",
    "def speed_up_audio(audio_data, factor=1.1):\n",
    "    \"\"\"Speed up recording by interpolation\n",
    "\n",
    "    The total number of samples is reduced by `factor` which leads\n",
    "    to a shorter recording when `factor>1`.\n",
    "    \"\"\"\n",
    "    xp = array_api_compat.get_namespace(audio_data)\n",
    "\n",
    "    new_audio = xp.interp(\n",
    "        xp.arange(0, len(audio_data), factor, device=audio_data.device),\n",
    "        xp.arange(len(audio_data), device=audio_data.device),\n",
    "        audio_data,\n",
    "    )\n",
    "\n",
    "    return new_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bada9-3f3f-4ffb-bd40-0c2547ca73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "audio_torch = torch.asarray(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87046d33-b056-4e34-b4a0-a1b346ca5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_audio(audio_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf5b9d-97b5-4276-9189-9c79c600bee5",
   "metadata": {},
   "source": [
    "It is of course not that easy.\n",
    "\n",
    "The array API standard does not cover all functions that exist in Numpy.\n",
    "\n",
    "So we will have to write our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520d762-343b-4baf-bf34-dc086fae054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(x, xp, fp):\n",
    "    \"\"\"Interpolate a function at the points `x`\n",
    "\n",
    "    The original function is represented by points `xp` where the function\n",
    "    has the value `fp`. The interpolated result is calculated by interpolating\n",
    "    the points of the function closes to each point in `x`.\n",
    "    \"\"\"\n",
    "    # This ensures all three arrays are from the same namespace\n",
    "    xp_ = array_api_compat.get_namespace(x, xp, fp)\n",
    "    \n",
    "    y = xp_.zeros_like(x)\n",
    "    # Assume `x` is sorted, like `xp`\n",
    "    idx = 0\n",
    "    for n, xi in enumerate(x):\n",
    "        if xi < xp[0]:\n",
    "            y[n] = fp[0]\n",
    "        elif xi > xp[-1]:\n",
    "            y[n] = fp[-1]\n",
    "        else:\n",
    "            while xi > xp[idx + 1]:\n",
    "                idx += 1\n",
    "            y[n] = fp[idx] + (fp[idx + 1] - fp[idx]) * (xi - xp[idx]) / (xp[idx + 1] - xp[idx])\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcca70-1697-4ce1-9c5e-c8ad866be1a4",
   "metadata": {},
   "source": [
    "Quick little sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa3324-3ebe-45c6-8486-ebf005aaa76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp(np.asarray((2, 2.5,)), np.asarray([1., 2., 3.]), np.asarray([2., 3, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13581b8-4d01-4fba-a291-194f42ffa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_up_audio(audio_data, factor=1.1):\n",
    "    \"\"\"Speed up recording by interpolation\n",
    "\n",
    "    The total number of samples is reduced by `factor` which leads\n",
    "    to a shorter recording when `factor>1`.\n",
    "    \"\"\"\n",
    "    xp = array_api_compat.get_namespace(audio_data)\n",
    "\n",
    "    new_audio = interp(\n",
    "        xp.arange(0, len(audio_data), factor, device=audio_data.device),\n",
    "        xp.arange(len(audio_data), device=audio_data.device),\n",
    "        audio_data,\n",
    "    )\n",
    "\n",
    "    return new_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142be7e8-f83f-4f50-af92-df8e34be576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_audio_torch = speed_up_audio(audio_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb988a-ce33-4eb6-af65-1f0df4411deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert the result back to Numpy because the `Audio` widget\n",
    "# does not use the array API :-)\n",
    "Audio(fast_audio_torch.numpy(), rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
