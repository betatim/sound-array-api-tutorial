{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bce6ce95-d6a7-4ab5-80e8-576cbd2592f2",
      "metadata": {
        "id": "bce6ce95-d6a7-4ab5-80e8-576cbd2592f2"
      },
      "source": [
        "# Sound Effects\n",
        "\n",
        "Let's implement some simple sound effects in Numpy and then translate them to use the array API."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uv8lE62gR8vS",
      "metadata": {
        "id": "Uv8lE62gR8vS"
      },
      "source": [
        "## Preparations\n",
        "\n",
        "We will need a simple guitar sound file and install a helper library for later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1eNAsadSHhC",
      "metadata": {
        "id": "e1eNAsadSHhC"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/betatim/sound-array-api-tutorial/raw/main/guitar.wav\n",
        "!pip install array-api-compat ipywebrtc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o0keMH__SHOR",
      "metadata": {
        "id": "o0keMH__SHOR"
      },
      "source": [
        "## Implementing a Tremolo Effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b4c518-d186-4c4b-92b1-44c5847941e4",
      "metadata": {
        "id": "b6b4c518-d186-4c4b-92b1-44c5847941e4"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ccaee8-4cea-4f75-8fe7-1425991f7d1a",
      "metadata": {
        "id": "b4ccaee8-4cea-4f75-8fe7-1425991f7d1a"
      },
      "source": [
        "To get started we have a recording of someone playing a few notes on a guitar.\n",
        "\n",
        "The effect we will apply is called Tremolo. You probably have heard it before in a song,\n",
        "but like me might not know it by name.\n",
        "\n",
        "What it does is modulate the amplitude (loudness) of the recording with a low\n",
        "frequency. Typically a few Hertz."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HxGJhOtAS5ko",
      "metadata": {
        "id": "HxGJhOtAS5ko"
      },
      "source": [
        "\n",
        "First, let's load a guitar recording:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e20ce2-58fc-4949-ab92-e7c964610647",
      "metadata": {
        "id": "49e20ce2-58fc-4949-ab92-e7c964610647"
      },
      "outputs": [],
      "source": [
        "rate, guitar = scipy.io.wavfile.read(\"guitar.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q9Tdcv4YS6t5",
      "metadata": {
        "id": "Q9Tdcv4YS6t5"
      },
      "source": [
        "The recording is returned as a sampling `rate` in Herz and the NumPy array `guitar`. We can use the `Audio` widget to listen to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4c1816-3a1d-4332-acda-378234b95565",
      "metadata": {
        "id": "0e4c1816-3a1d-4332-acda-378234b95565"
      },
      "outputs": [],
      "source": [
        "Audio(guitar, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A9yN2WT1TSz4",
      "metadata": {
        "id": "A9yN2WT1TSz4"
      },
      "source": [
        "### NumPy Implementation of the Tremolo Effect\n",
        "\n",
        "Below you will find a NumPy implementation of the tremolo effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092650df-40f9-463b-b079-dc6f5e962e72",
      "metadata": {
        "id": "092650df-40f9-463b-b079-dc6f5e962e72"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def simple_tremolo(audio, frequency, depth, sample_rate=44100):\n",
        "    \"\"\"\n",
        "    Apply a simple tremolo effect to the input audio signal.\n",
        "\n",
        "    Parameters:\n",
        "    - audio (ndarray): Input audio signal\n",
        "    - frequency (float): Frequency of the tremolo effect (Hz)\n",
        "    - depth (float): Magnitude of the tremolo effect (0-1)\n",
        "\n",
        "    Returns:\n",
        "    - ndarray: Output audio signal with tremolo effect\n",
        "    \"\"\"\n",
        "    t = np.arange(len(audio)) / float(sample_rate)\n",
        "    modulator = np.sin(2 * np.pi * frequency * t) # / 2 + 0.5\n",
        "    output = audio * (1 + depth * modulator)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tqT3sF6oTpKH",
      "metadata": {
        "id": "tqT3sF6oTpKH"
      },
      "source": [
        "Let's listen to it applied to our guitar signal.  You can play with the frequency and depths parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7276a2f5-fc9e-44b1-b8f3-a02656b58919",
      "metadata": {
        "id": "7276a2f5-fc9e-44b1-b8f3-a02656b58919"
      },
      "outputs": [],
      "source": [
        "Audio(simple_tremolo(guitar, 10, 0.65, sample_rate=rate), rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318b8ca2-52ea-4127-bb0f-b2ccf2f300cb",
      "metadata": {
        "id": "318b8ca2-52ea-4127-bb0f-b2ccf2f300cb"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "A few minutes break for you to implement a version that uses the array API."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2r8IA0XnVrsE",
      "metadata": {
        "id": "2r8IA0XnVrsE"
      },
      "source": [
        "Below some imports that will be useful.  We also define a function to convert back to NumPy since the `Audio` widget does not work with GPU arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37db1cd7-aaaf-485d-a166-7971b4d90c0b",
      "metadata": {
        "id": "37db1cd7-aaaf-485d-a166-7971b4d90c0b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import array_api_compat\n",
        "\n",
        "\n",
        "def convert_to_numpy(array, xp=None):\n",
        "    \"\"\"Convert X into a NumPy ndarray on the CPU.\"\"\"\n",
        "    # Note: In the future, `np.from_dlpack()` may be enough for this.\n",
        "    if xp is None:\n",
        "        xp = array_api_compat.get_namespace(array)\n",
        "    xp_name = xp.__name__\n",
        "\n",
        "    if xp_name in {\"array_api_compat.torch\", \"torch\"}:\n",
        "        return array.cpu().numpy()\n",
        "    elif xp_name == \"cupy.array_api\":\n",
        "        return array._array.get()\n",
        "    elif xp_name in {\"array_api_compat.cupy\", \"cupy\"}:\n",
        "        return array.get()\n",
        "\n",
        "    return np.asarray(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fycjZN3QVu_4",
      "metadata": {
        "id": "fycjZN3QVu_4"
      },
      "source": [
        "The `guitar` numpy array has been converted to a PyTorch array, but you can also try using CuPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z7WtH8I8VwM3",
      "metadata": {
        "id": "z7WtH8I8VwM3"
      },
      "outputs": [],
      "source": [
        "guitar_torch = torch.asarray(guitar, device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CG0baUdTWkoa",
      "metadata": {
        "id": "CG0baUdTWkoa"
      },
      "source": [
        "Try running the tremolo below with a torch tensor.  Since it is on the GPU, this will fail.  If it was a torch CPU tensor it would succeed but still use NumPy.\n",
        "\n",
        "After trying this, rewrite `simple_tremolo` to be Array API compatible!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f92cec-e0f5-42b7-b67a-0c3c2c7dcc9a",
      "metadata": {
        "id": "f3f92cec-e0f5-42b7-b67a-0c3c2c7dcc9a"
      },
      "outputs": [],
      "source": [
        "# Modify this function to use the Array API\n",
        "\n",
        "def simple_tremolo(audio, frequency, depth, sample_rate=44100):\n",
        "    t = np.arange(len(audio)) / float(sample_rate)\n",
        "    modulator = np.sin(2 * np.pi * frequency * t) # / 2 + 0.5\n",
        "    output = audio * (1 + depth * modulator)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba72d24-31f9-45d0-9a20-6266889e9831",
      "metadata": {
        "id": "dba72d24-31f9-45d0-9a20-6266889e9831"
      },
      "outputs": [],
      "source": [
        "tremolo_guitar = simple_tremolo(guitar_torch, 10, 0.65, sample_rate=rate)\n",
        "\n",
        "Audio(convert_to_numpy(tremolo_guitar), rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bxICM74XKW_",
      "metadata": {
        "id": "1bxICM74XKW_"
      },
      "source": [
        "To show that this worked, try timing both with the %timeit magic! The NumPy version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WBYGMCGzXRCt",
      "metadata": {
        "id": "WBYGMCGzXRCt"
      },
      "outputs": [],
      "source": [
        "%timeit simple_tremolo(guitar, 10, 0.65, sample_rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nHhv2ugTYEqC",
      "metadata": {
        "id": "nHhv2ugTYEqC"
      },
      "source": [
        "And your version with torch or cupy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QCExiOEHYBlz",
      "metadata": {
        "id": "QCExiOEHYBlz"
      },
      "outputs": [],
      "source": [
        "# Time your array API version with the GPU data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e3e0e8-db89-4840-8d4b-2cccef30c801",
      "metadata": {
        "id": "e6e3e0e8-db89-4840-8d4b-2cccef30c801"
      },
      "source": [
        "## Visualisation\n",
        "\n",
        "The tremolo effect is nice because you can hear it and it is easy to visualise when looking at the waveform.\n",
        "\n",
        "Let's do some plotting with the `librosa` library that has useful built in visualisation tools.\n",
        "\n",
        "One thing to note is that `librosa` does not use the array API, like `matplotlib`, which means\n",
        "we will need to convert our PyTorch array to a Numpy array. Currently this requires a small\n",
        "library aware conversion function. Different array libraries have different methods for\n",
        "allowing you to convert back to a Numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09527f95-65ce-42a8-8578-d5a45e94ebea",
      "metadata": {
        "id": "09527f95-65ce-42a8-8578-d5a45e94ebea"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824b9064-bb27-498d-8cf3-6814eee94b71",
      "metadata": {
        "id": "824b9064-bb27-498d-8cf3-6814eee94b71"
      },
      "outputs": [],
      "source": [
        "def waveshow(data, title=\"Amplitude\"):\n",
        "    xp = array_api_compat.get_namespace(data)\n",
        "    data = xp.astype(data, xp.float32)\n",
        "    data /= xp.max(xp.abs(data))\n",
        "\n",
        "    data_np = convert_to_numpy(data, xp)\n",
        "    librosa.display.waveshow(data_np, sr=44100)\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999c3e1b-ae1b-4849-a6d8-5dfb9e6a9306",
      "metadata": {
        "id": "999c3e1b-ae1b-4849-a6d8-5dfb9e6a9306"
      },
      "outputs": [],
      "source": [
        "# Selecting one second from the sample where a note is being played\n",
        "one_second = slice(int(1.5*rate), int(2.5*rate))\n",
        "\n",
        "waveshow(guitar[one_second], title=\"Original guitar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d2cb43-9550-478f-a12b-0af4de26d69c",
      "metadata": {
        "id": "d7d2cb43-9550-478f-a12b-0af4de26d69c"
      },
      "outputs": [],
      "source": [
        "tremolo_guitar = simple_tremolo(guitar_torch, 10, 0.65, sample_rate=rate)\n",
        "waveshow(tremolo_guitar[one_second], title=\"Tremolo guitar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd685fe-5644-42a9-9ba0-a8e30ff005af",
      "metadata": {
        "id": "5cd685fe-5644-42a9-9ba0-a8e30ff005af"
      },
      "source": [
        "## Recording some audio\n",
        "\n",
        "We need some sound to work on. Luckily we can just record something with the microphone in our computers.\n",
        "\n",
        "Note: if recording a custom audio does not work for you, simply keep using the guitar audio!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e19c869-db64-47d4-8172-b71de485bb9d",
      "metadata": {
        "id": "2e19c869-db64-47d4-8172-b71de485bb9d"
      },
      "outputs": [],
      "source": [
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "\n",
        "# On colab, uncomment these lines (or colab will ask later)\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e3366d-508e-48f7-a181-38d8e3373dde",
      "metadata": {
        "id": "a6e3366d-508e-48f7-a181-38d8e3373dde"
      },
      "outputs": [],
      "source": [
        "def record_audio():\n",
        "    camera = CameraStream(constraints={'audio': True, 'video': False})\n",
        "    recorder = AudioRecorder(stream=camera)\n",
        "    return recorder\n",
        "\n",
        "def convert_audio(recorder):\n",
        "    recorder.save(\"recording.webm\")\n",
        "    !ffmpeg -i recording.webm -ac 1 -ar 44100 -f wav my_recording.wav -y -hide_banner -loglevel panic\n",
        "\n",
        "    rate, rec = scipy.io.wavfile.read(\"my_recording.wav\")\n",
        "\n",
        "    return rate, rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a913bec-b3a5-412a-81d5-0520e21065b2",
      "metadata": {
        "id": "2a913bec-b3a5-412a-81d5-0520e21065b2"
      },
      "outputs": [],
      "source": [
        "recorder = record_audio()\n",
        "recorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "611eecb1-20a3-44d9-81d8-d664d7c729de",
      "metadata": {
        "id": "611eecb1-20a3-44d9-81d8-d664d7c729de"
      },
      "outputs": [],
      "source": [
        "sample_rate, audio = convert_audio(recorder)\n",
        "\n",
        "# Or use the guitar audio:\n",
        "#sample_rate, audio = scipy.io.wavfile.read(\"guitar.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df705c71-f3dd-44dc-ac68-53e07737b139",
      "metadata": {
        "id": "df705c71-f3dd-44dc-ac68-53e07737b139"
      },
      "source": [
        "## Extension if time: Speeding up a recording\n",
        "\n",
        "You all know the \"playback speed\" button on YouTube. Let's implement a simple version of this.\n",
        "\n",
        "When we record sound we create a set of samples. Typically something like 20000 samples per second. This means a one second\n",
        "recording contains about 20000 samples. To play back a recording at the right speed we need to know the sample rate,\n",
        "how many samples were recorded per second.\n",
        "\n",
        "To speed up a recording by ten percent we can take an existing 5second recording made of `100_000` samples and reduce the total number\n",
        "of samples to `100_000 / 1.1 = 90910` samples. When we then play back this smaller number of samples at the same rate, we will get\n",
        "a shorter recording."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c82a0b-24b7-4c21-a457-11269dd42aa5",
      "metadata": {
        "id": "29c82a0b-24b7-4c21-a457-11269dd42aa5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def speed_up_audio(audio_data, factor=1.1):\n",
        "    \"\"\"Speed up recording by interpolation\n",
        "\n",
        "    The total number of samples is reduced by `factor` which leads\n",
        "    to a shorter recording when `factor>1`.\n",
        "    \"\"\"\n",
        "    new_audio = np.interp(\n",
        "        np.arange(0, len(audio_data), factor),\n",
        "        np.arange(len(audio_data)),\n",
        "        audio_data,\n",
        "    )\n",
        "    return new_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce7351a-9bc8-4dba-8f93-de902bb6a5fc",
      "metadata": {
        "id": "3ce7351a-9bc8-4dba-8f93-de902bb6a5fc"
      },
      "outputs": [],
      "source": [
        "fast_audio = speed_up_audio(audio, 1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6142f2-6f10-4d59-b309-967b579e25dc",
      "metadata": {
        "id": "5b6142f2-6f10-4d59-b309-967b579e25dc"
      },
      "outputs": [],
      "source": [
        "Audio(fast_audio, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ae44a8a-d388-4e31-aa94-a481b09bcdb6",
      "metadata": {
        "id": "0ae44a8a-d388-4e31-aa94-a481b09bcdb6"
      },
      "source": [
        "The basics work, so lets re-implement this using the array API so that it works with CuPy, PyTorch and Numpy arrays.\n",
        "\n",
        "The speed up function looks pretty straightforward so it should be easy to convert it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25daaf8f-ab5e-4b3f-b5c2-f95ff8e40153",
      "metadata": {
        "id": "25daaf8f-ab5e-4b3f-b5c2-f95ff8e40153"
      },
      "outputs": [],
      "source": [
        "import array_api_compat\n",
        "\n",
        "\n",
        "def speed_up_audio(audio_data, factor=1.1):\n",
        "    \"\"\"Speed up recording by interpolation\n",
        "\n",
        "    The total number of samples is reduced by `factor` which leads\n",
        "    to a shorter recording when `factor>1`.\n",
        "    \"\"\"\n",
        "    xp = array_api_compat.get_namespace(audio_data)\n",
        "\n",
        "    new_audio = xp.interp(\n",
        "        xp.arange(0, len(audio_data), factor, device=audio_data.device),\n",
        "        xp.arange(len(audio_data), device=audio_data.device),\n",
        "        audio_data,\n",
        "    )\n",
        "\n",
        "    return new_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb5bada9-3f3f-4ffb-bd40-0c2547ca73e7",
      "metadata": {
        "id": "fb5bada9-3f3f-4ffb-bd40-0c2547ca73e7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "audio_torch = torch.asarray(audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87046d33-b056-4e34-b4a0-a1b346ca5ff3",
      "metadata": {
        "id": "87046d33-b056-4e34-b4a0-a1b346ca5ff3"
      },
      "outputs": [],
      "source": [
        "speed_up_audio(audio_torch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdf5b9d-97b5-4276-9189-9c79c600bee5",
      "metadata": {
        "id": "dfdf5b9d-97b5-4276-9189-9c79c600bee5"
      },
      "source": [
        "It is of course not that easy.\n",
        "\n",
        "The array API standard does not cover all functions that exist in Numpy.\n",
        "\n",
        "So we will have to write our own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8520d762-343b-4baf-bf34-dc086fae054f",
      "metadata": {
        "id": "8520d762-343b-4baf-bf34-dc086fae054f"
      },
      "outputs": [],
      "source": [
        "def interp(x, xp, fp):\n",
        "    \"\"\"Interpolate a function at the points `x`\n",
        "\n",
        "    The original function is represented by points `xp` where the function\n",
        "    has the value `fp`. The interpolated result is calculated by interpolating\n",
        "    the points of the function closes to each point in `x`.\n",
        "    \"\"\"\n",
        "    # The Array API does support searchsorted, so we can get a decent speed with it.\n",
        "    # In principle, we don't need a full interpolate since xp is regular.\n",
        "    xp_ = array_api_compat.get_namespace(x, xp, fp)\n",
        "\n",
        "    upper = xp_.searchsorted(xp, x, side=\"right\")\n",
        "    lower = upper - 1\n",
        "    if xp_.any((upper < 1) | (upper >= len(xp))):\n",
        "        raise ValueError(\"Cannot interpolate outside range.\")\n",
        "\n",
        "    spacing = xp[upper] - xp[lower]\n",
        "    spacing[spacing == 0] = 1  # avoid NaN values (should not happen)\n",
        "\n",
        "    frac = (x - xp[lower]) / spacing\n",
        "    return fp[lower] * (1 - frac) + fp[upper] * frac"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cdcca70-1697-4ce1-9c5e-c8ad866be1a4",
      "metadata": {
        "id": "3cdcca70-1697-4ce1-9c5e-c8ad866be1a4"
      },
      "source": [
        "Quick little sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03aa3324-3ebe-45c6-8486-ebf005aaa76c",
      "metadata": {
        "id": "03aa3324-3ebe-45c6-8486-ebf005aaa76c"
      },
      "outputs": [],
      "source": [
        "interp(np.asarray([2, 2.5]), np.asarray([1., 2., 3.]), np.asarray([2., 3, 5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13581b8-4d01-4fba-a291-194f42ffa957",
      "metadata": {
        "id": "a13581b8-4d01-4fba-a291-194f42ffa957"
      },
      "outputs": [],
      "source": [
        "def speed_up_audio(audio_data, factor=1.1):\n",
        "    \"\"\"Speed up recording by interpolation\n",
        "\n",
        "    The total number of samples is reduced by `factor` which leads\n",
        "    to a shorter recording when `factor>1`.\n",
        "    \"\"\"\n",
        "    xp = array_api_compat.get_namespace(audio_data)\n",
        "\n",
        "    new_audio = interp(\n",
        "        xp.arange(0, len(audio_data), factor, device=audio_data.device),\n",
        "        xp.arange(len(audio_data), device=audio_data.device),\n",
        "        audio_data,\n",
        "    )\n",
        "\n",
        "    return new_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142be7e8-f83f-4f50-af92-df8e34be576d",
      "metadata": {
        "id": "142be7e8-f83f-4f50-af92-df8e34be576d"
      },
      "outputs": [],
      "source": [
        "fast_audio_torch = speed_up_audio(audio_torch, 2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afb988a-ce33-4eb6-af65-1f0df4411deb",
      "metadata": {
        "id": "6afb988a-ce33-4eb6-af65-1f0df4411deb"
      },
      "outputs": [],
      "source": [
        "# We have to convert the result back to Numpy because the `Audio` widget\n",
        "# does not use the array API :-)\n",
        "Audio(convert_to_numpy(fast_audio_torch), rate=sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u75duAZU3hYz"
      },
      "id": "u75duAZU3hYz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}